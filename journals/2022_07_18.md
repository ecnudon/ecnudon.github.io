- [[论文]]
	- [[PERFECT: Prompt-free and Efficient Few-shot Learning with Language Models]] #Few-shot
		- 📌[[要点]]
		- 💡  [[想法]]
			- 一个token可能信息不太足, 所以文中用了$M$个token, 本质作用其实用一个完全可以(但这只是理论依据)
			- 但是之后为什么又用prototype了? 感觉上面练出来的那个模型没啥用
		- TODO 完成阅读
		- TODO ^^需要精读!^^
- 下一篇论文就是PET论文, 因为有对比所以两篇文章一起看看
- [[论文]]
	- [[Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference]] #Few-shot
		- 📌[[要点]]
		- 💡  [[想法]]
		- TODO 完成阅读
		- TODO ^^需要精读!^^