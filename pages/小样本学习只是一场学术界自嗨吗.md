title:: 小样本学习只是一场学术界自嗨吗
website-title:: 微信公众平台
item-type:: [[webpage]]
access-date:: 2022-07-04
original-title:: 小样本学习只是一场学术界自嗨吗
url:: http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247526233&idx=1&sn=49a2cacdcc00f792735e49f530042263&chksm=970f4f8fa078c6994d8790269ab5ae49969feb5fe9b942621c99c4f659ba2c9bad1d974314b1#rd
authors:: [[ALme]], [[夕小瑶的卖萌屋]]
links:: [Local library](zotero://select/library/items/RSI5KH3V), [Web library](https://www.zotero.org/users/9034808/items/RSI5KH3V)

- [[Abstract]]
	- 大型自嗨还是真有意义？
- [[Attachments]]
	- [Snapshot](https://mp.weixin.qq.com/s/hRoFMGtNg6OX_Ik5OpUXAQ) {{zotero-imported-file QB4SQTY7, "hRoFMGtNg6OX_Ik5OpUXAQ.html"}}
- title:: 小样本学习只是一场学术界自嗨吗
  website-title:: 微信公众平台
  item-type:: [[webpage]]
  access-date:: 2022-07-04
  original-title:: 小样本学习只是一场学术界自嗨吗
  url:: http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247526233&idx=1&sn=49a2cacdcc00f792735e49f530042263&chksm=970f4f8fa078c6994d8790269ab5ae49969feb5fe9b942621c99c4f659ba2c9bad1d974314b1#rd
  authors:: [[ALme]], [[夕小瑶的卖萌屋]]
  links:: [Local library](zotero://select/library/items/RSI5KH3V), [Web library](https://www.zotero.org/users/9034808/items/RSI5KH3V)
- [[Abstract]]
	- 大型自嗨还是真有意义？
- [[Attachments]]
	- [Snapshot](https://mp.weixin.qq.com/s/hRoFMGtNg6OX_Ik5OpUXAQ) {{zotero-imported-file QB4SQTY7, "hRoFMGtNg6OX_Ik5OpUXAQ.html"}}
- [[note]]
	- 现在的机器学习, 使用预训练模型提取特征, 在新数据集上进行微调(fine-tune)
	- few-shot learning本质上就是一种transfer learning,
	- 需要注意, transfer learning的问题:
		- 训练和微调的domain是不同的 (看wiki, 识别军事)
		- category也不同 (看作家歌手, 识别舰艇飞机)
	- 而few-shot learning的目标域的labeled data也是缺少的.
	- 2019论文 *Do Better ImageNet Models Transfer Better?* 实验结果:
		- 目标域数据量较大的情况下, finetune有更好的效果 (不满足few-shot)
		- Few-shot的背景下, 冻住backbone, 再加一个Linear Logistic 分类器效果更好
		- 说明: finetune效果和目标域labeled data数据量正相关
	- Big Transfer论文(稍后看)
		- 感觉意思是: 好的表现的最终解决方法都是『不few』
	- 另一个问题, 如何最大化利用support set 少量图片的representation去构造一个好的分类器呢
		- 这是导致Few-shot learning 百花齐放的一点
		- meta learning 的问题: 训练源数据分布和测试时的目标源数据分布不同, 同分布假设一开始就不成立
	- 另外的问题:
		- 因为目标域labeled data少, 而且类别没见过
		- 所以特征的提取也可能存在问题.
	- 『可以看到，训练学得一个good representation，和测试时从有限labeled data建立一个好的分类器在一般的任务中是可以统一起来的。但在few-shot learning中，随着元学习方法的缺点不断被挖掘，这两点割裂开来，成为两个独立的问题』
		- 前者探究representation在目标域labeled data是few-shot场景时所存在的核心问题
		- 后者涉及如何给定pretrained feature，做到快速task adaptation，核心:
			- 取pretrained feature之精华，去其糟粕
			- 从support set feature及目标query feature中最大化可用信息，比如从support set中找类内共性，或者找support feature和query feature之间的对应关系，或者从训练集中找寻并利用和support set的相似图片，这第二点可以统称为task adaptation。
-