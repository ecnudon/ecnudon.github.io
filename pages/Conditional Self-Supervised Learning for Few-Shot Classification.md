date:: 8/2021
publisher:: International Joint Conferences on Artificial Intelligence Organization
place:: "Montreal, Canada"
conference-name:: Thirtieth International Joint Conference on Artificial Intelligence {IJCAI-21}
proceedings-title:: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence
isbn:: 978-0-9992411-9-6
doi:: 10.24963/ijcai.2021/295
title:: Conditional Self-Supervised Learning for Few-Shot Classification
pages:: 2140-2146
item-type:: [[conferencePaper]]
access-date:: 2022-07-10T03:36:39Z
original-title:: Conditional Self-Supervised Learning for Few-Shot Classification
language:: en
url:: https://www.ijcai.org/proceedings/2021/295
authors:: [[Yuexuan An]], [[Hui Xue]], [[Xingyu Zhao]], [[Lu Zhang]]
library-catalog:: DOI.org (Crossref)
links:: [Local library](zotero://select/library/items/3KZTA393), [Web library](https://www.zotero.org/users/9034808/items/3KZTA393)

- [[Abstract]]
	- How to learn a transferable feature representation from limited examples is a key challenge for fewshot classiﬁcation. Self-supervision as an auxiliary task to the main supervised few-shot task is considered to be a conceivable way to solve the problem since self-supervision can provide additional structural information easily ignored by the main task. However, learning a good representation by traditional self-supervised methods is usually dependent on large training samples. In few-shot scenarios, due to the lack of sufﬁcient samples, these self-supervised methods might learn a biased representation, which more likely leads to the wrong guidance for the main tasks and ﬁnally causes the performance degradation. In this paper, we propose conditional self-supervised learning (CSS) to use prior knowledge to guide the representation learning of self-supervised tasks. Speciﬁcally, CSS leverages inherent supervised information in labeled data to shape and improve the learning feature manifold of self-supervision without auxiliary unlabeled data, so as to reduce representation bias and mine more effective semantic information. Moreover, CSS exploits more meaningful information through supervised learning and the improved self-supervised learning respectively and integrates the information into a uniﬁed distribution, which can further enrich and broaden the original representation. Extensive experiments demonstrate that our proposed method without any ﬁne-tuning can achieve a signiﬁcant accuracy improvement on the few-shot classiﬁcation scenarios compared to the state-of-the-art few-shot learning methods.
- [[Attachments]]
	- [An 等。 - 2021 - Conditional Self-Supervised Learning for Few-Shot .pdf](https://www.ijcai.org/proceedings/2021/0295.pdf) {{zotero-imported-file 8XH23AJ7, "An 等。 - 2021 - Conditional Self-Supervised Learning for Few-Shot .pdf"}}