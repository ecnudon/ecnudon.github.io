date:: 8/2021
publisher:: International Joint Conferences on Artificial Intelligence Organization
place:: "Montreal, Canada"
conference-name:: Thirtieth International Joint Conference on Artificial Intelligence {IJCAI-21}
proceedings-title:: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence
isbn:: 978-0-9992411-9-6
doi:: 10.24963/ijcai.2021/295
title:: Conditional Self-Supervised Learning for Few-Shot Classification
pages:: 2140-2146
item-type:: [[conferencePaper]]
access-date:: 2022-07-10T03:36:39Z
original-title:: Conditional Self-Supervised Learning for Few-Shot Classification
language:: en
url:: https://www.ijcai.org/proceedings/2021/295
authors:: [[Yuexuan An]], [[Hui Xue]], [[Xingyu Zhao]], [[Lu Zhang]]
library-catalog:: DOI.org (Crossref)
links:: [Local library](zotero://select/library/items/3KZTA393), [Web library](https://www.zotero.org/users/9034808/items/3KZTA393)

- [[Abstract]]
	- How to learn a transferable feature representation from limited examples is a key challenge for fewshot classiﬁcation. Self-supervision as an auxiliary task to the main supervised few-shot task is considered to be a conceivable way to solve the problem since self-supervision can provide additional structural information easily ignored by the main task. However, learning a good representation by traditional self-supervised methods is usually dependent on large training samples. In few-shot scenarios, due to the lack of sufﬁcient samples, these self-supervised methods might learn a biased representation, which more likely leads to the wrong guidance for the main tasks and ﬁnally causes the performance degradation. In this paper, we propose conditional self-supervised learning (CSS) to use prior knowledge to guide the representation learning of self-supervised tasks. Speciﬁcally, CSS leverages inherent supervised information in labeled data to shape and improve the learning feature manifold of self-supervision without auxiliary unlabeled data, so as to reduce representation bias and mine more effective semantic information. Moreover, CSS exploits more meaningful information through supervised learning and the improved self-supervised learning respectively and integrates the information into a uniﬁed distribution, which can further enrich and broaden the original representation. Extensive experiments demonstrate that our proposed method without any ﬁne-tuning can achieve a signiﬁcant accuracy improvement on the few-shot classiﬁcation scenarios compared to the state-of-the-art few-shot learning methods.
- [[Attachments]]
	- [An 等。 - 2021 - Conditional Self-Supervised Learning for Few-Shot .pdf](https://www.ijcai.org/proceedings/2021/0295.pdf) {{zotero-imported-file 8XH23AJ7, "An 等。 - 2021 - Conditional Self-Supervised Learning for Few-Shot .pdf"}}
-
- date:: 8/2021
  publisher:: International Joint Conferences on Artificial Intelligence Organization
  place:: "Montreal, Canada"
  conference-name:: Thirtieth International Joint Conference on Artificial Intelligence {IJCAI-21}
  proceedings-title:: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence
  isbn:: 978-0-9992411-9-6
  doi:: 10.24963/ijcai.2021/295
  title:: Conditional Self-Supervised Learning for Few-Shot Classification
  pages:: 2140-2146
  item-type:: [[conferencePaper]]
  access-date:: 2022-07-10T03:36:39Z
  original-title:: Conditional Self-Supervised Learning for Few-Shot Classification
  language:: en
  url:: https://www.ijcai.org/proceedings/2021/295
  authors:: [[Yuexuan An]], [[Hui Xue]], [[Xingyu Zhao]], [[Lu Zhang]]
  library-catalog:: DOI.org (Crossref)
  links:: [Local library](zotero://select/library/items/3KZTA393), [Web library](https://www.zotero.org/users/9034808/items/3KZTA393)
- [[Abstract]]
	- How to learn a transferable feature representation from limited examples is a key challenge for fewshot classiﬁcation. Self-supervision as an auxiliary task to the main supervised few-shot task is considered to be a conceivable way to solve the problem since self-supervision can provide additional structural information easily ignored by the main task. However, learning a good representation by traditional self-supervised methods is usually dependent on large training samples. In few-shot scenarios, due to the lack of sufﬁcient samples, these self-supervised methods might learn a biased representation, which more likely leads to the wrong guidance for the main tasks and ﬁnally causes the performance degradation. In this paper, we propose conditional self-supervised learning (CSS) to use prior knowledge to guide the representation learning of self-supervised tasks. Speciﬁcally, CSS leverages inherent supervised information in labeled data to shape and improve the learning feature manifold of self-supervision without auxiliary unlabeled data, so as to reduce representation bias and mine more effective semantic information. Moreover, CSS exploits more meaningful information through supervised learning and the improved self-supervised learning respectively and integrates the information into a uniﬁed distribution, which can further enrich and broaden the original representation. Extensive experiments demonstrate that our proposed method without any ﬁne-tuning can achieve a signiﬁcant accuracy improvement on the few-shot classiﬁcation scenarios compared to the state-of-the-art few-shot learning methods.
- [[Attachments]]
	- [An 等。 - 2021 - Conditional Self-Supervised Learning for Few-Shot .pdf](https://www.ijcai.org/proceedings/2021/0295.pdf) {{zotero-imported-file 8XH23AJ7, "An 等。 - 2021 - Conditional Self-Supervised Learning for Few-Shot .pdf"}}
- date:: [[Mon, 2021/08/09]]
  conference-name:: Twenty-Ninth International Joint Conference on Artificial Intelligence
  extra:: ISSN: 1045-0823
  doi:: 10.24963/ijcai.2021/295
  title:: Conditional Self-Supervised Learning for Few-Shot Classification
  pages:: 2140-2146
  volume:: 3
  item-type:: [[conferencePaper]]
  access-date:: 2022-07-11T03:22:15Z
  original-title:: Conditional Self-Supervised Learning for Few-Shot Classification
  language:: en
  url:: https://www.ijcai.org/proceedings/2021/295
  authors:: [[Yuexuan An]], [[Hui Xue]], [[Xingyu Zhao]], [[Lu Zhang]]
  library-catalog:: www.ijcai.org
  links:: [Local library](zotero://select/library/items/N3PBV23T), [Web library](https://www.zotero.org/users/9034808/items/N3PBV23T)
- [[Abstract]]
	- Electronic proceedings of IJCAI 2021
- [[Attachments]]
	- [Conditional Self-Supervised Learning for Few-Shot Classification_2021_An_Xue_Zhao_Zhang_.pdf](zotero://select/library/items/RBVAQ7EP) {{zotero-linked-file "attachments:Few-shot/Conditional Self-Supervised Learning for Few-Shot Classification_2021_An_Xue_Zhao_Zhang_.pdf"}}
	- [Snapshot](https://www.ijcai.org/proceedings/2021/295) {{zotero-imported-file Y6F7RHRZ, "295.html"}}
- date:: [[Mon, 2021/08/09]]
  conference-name:: Twenty-Ninth International Joint Conference on Artificial Intelligence
  extra:: ISSN: 1045-0823
  doi:: 10.24963/ijcai.2021/295
  title:: Conditional Self-Supervised Learning for Few-Shot Classification
  pages:: 2140-2146
  volume:: 3
  item-type:: [[conferencePaper]]
  access-date:: 2022-07-11T03:22:15Z
  original-title:: Conditional Self-Supervised Learning for Few-Shot Classification
  language:: en
  url:: https://www.ijcai.org/proceedings/2021/295
  authors:: [[Yuexuan An]], [[Hui Xue]], [[Xingyu Zhao]], [[Lu Zhang]]
  library-catalog:: www.ijcai.org
  links:: [Local library](zotero://select/library/items/N3PBV23T), [Web library](https://www.zotero.org/users/9034808/items/N3PBV23T)
- [[Abstract]]
	- Electronic proceedings of IJCAI 2021
- [[Attachments]]
	- [Conditional Self-Supervised Learning for Few-Shot Classification_2021_An_Xue_Zhao_Zhang_.pdf](zotero://select/library/items/RBVAQ7EP) {{zotero-linked-file "attachments:Few-shot/Conditional Self-Supervised Learning for Few-Shot Classification_2021_An_Xue_Zhao_Zhang_.pdf"}}
	- [Snapshot](https://www.ijcai.org/proceedings/2021/295) {{zotero-imported-file Y6F7RHRZ, "295.html"}}